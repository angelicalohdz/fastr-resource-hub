---
marp: true
theme: fastr
paginate: true
---

# Monitoring Service Delivery Trends

Detecting when health services are disrupted and measuring the impact

---

## Why Monitor Service Trends?

**The question:** Are health services being delivered consistently over time?

**Why it matters:**
- Services might drop during strikes, outbreaks, or supply shortages
- Services might surge during campaigns or after reforms
- We need to know when changes happen and how big they are

**FASTR helps you:**
- Spot when services deviate from normal patterns
- Measure how many services were missed (or exceeded)
- Identify which areas are most affected

---

## What We Mean by "Service Disruption"

**A disruption is when service delivery is significantly different from what we'd normally expect.**

**Examples of disruptions:**
- **Negative:** ANC visits drop by 30% during a health worker strike
- **Positive:** Vaccination rates surge during a catch-up campaign
- **Sustained:** Deliveries remain low for 6 months due to facility closure

**Not a disruption:**
- Small month-to-month variation (normal fluctuation)
- Predictable seasonal patterns (like malaria during rainy season)

---

## Two Key Questions FASTR Answers

**Question 1: WHEN did disruptions happen?**
- Which months showed unusual patterns?
- Were disruptions one-time events or sustained over months?

**Question 2: HOW MUCH was the impact?**
- How many services were missed during disruptions?
- What percentage drop occurred?
- Which areas had the biggest shortfalls?

**Together:** Identify problems + quantify their size = better targeted responses

---

## How FASTR Detects Disruptions

---

## Step 1: Understanding "Normal"

**Before we can spot problems, we need to know what's normal for each area and service.**

**FASTR looks at historical patterns:**
- What's the typical number of ANC visits in Province X each month?
- Is there a seasonal pattern? (Some services naturally higher in certain months)
- Is there a long-term trend? (Services increasing or decreasing over time)

**Example:**
- Province A normally has 800-900 ANC1 visits per month
- Slightly higher in dry season (better access)
- Gradually increasing trend (+2% per year)

---

## Step 2: Comparing Actual to Expected

**Once we know what's "normal," we compare actual service delivery to what we'd expect.**

**Example - Province A ANC1:**

| Month | Expected | Actual | Difference |
|-------|----------|--------|------------|
| Jan | 850 | 840 | -10 (normal variation) |
| Feb | 870 | 870 | 0 (right on track) |
| **Mar** | **860** | **620** | **-240** (**disruption**) |
| Apr | 880 | 890 | +10 (normal variation) |

**March shows a large drop** - this flags as a potential disruption needing investigation.

---

## Different Types of Disruptions

**FASTR looks for several disruption patterns:**

**1. Sharp drop or spike**
- One month with a very large change
- Example: Strike causes ANC to drop 40% in one month

**2. Gradual decline**
- Services slowly dropping over several months
- Example: Stock-outs cause steady decrease in deliveries

**3. Sustained low period**
- Services consistently below normal for months
- Example: Facility closure keeps immunizations low for 6 months

**4. Sustained surge**
- Services consistently above normal
- Example: Campaign boosts vaccination rates for 3 months

---

## Real Example: COVID-19 Disruption

**Country X - Institutional Deliveries:**

**Before COVID (Jan-Feb 2020):**
- Expected: ~10,000 deliveries/month
- Actual: 9,800-10,200 (normal range)

**During First Wave (Mar-Jun 2020):**
- Expected: ~10,000 deliveries/month
- Actual: 7,500-8,000 (**sustained disruption**)
- Impact: ~2,500 missed deliveries per month

**Recovery (Jul-Dec 2020):**
- Gradually returned toward normal
- By December: 9,500 deliveries

**FASTR detected:** When disruption started, its magnitude, and when recovery began.

---

## Measuring the Impact

---

## Calculating Service Shortfalls

**Once we identify a disruption, we measure its impact:**

**Shortfall = Expected Services - Actual Services**

**Example - District Y, March 2023:**
- Expected ANC4 visits: 1,200
- Actual ANC4 visits: 850
- **Shortfall: 350 visits (29% below expected)**

**Interpretation:** District Y missed about 350 ANC4 visits in March - these women didn't complete their antenatal care.

---

## Shortfalls vs. Surpluses

**Shortfall (negative disruption):**
- Fewer services delivered than expected
- Shows missed opportunities
- Requires catch-up efforts

**Surplus (positive disruption):**
- More services delivered than expected
- Could indicate successful campaign, policy change, or data quality issue
- Need to verify if it's real or a reporting problem

**Example surplus:**
- Vaccination campaign reaches 5,000 children
- Expected only 3,000 based on normal patterns
- Surplus: +2,000 vaccinations (positive outcome!)

---

## Geographic Detail: National vs. Local

**FASTR analyzes disruptions at multiple levels:**

**National level:**
- Overall country trends
- Big picture of health system performance

**Provincial/regional level:**
- Which provinces are most affected?
- Are disruptions concentrated geographically?

**District level (optional):**
- Most detailed view
- Identifies specific districts needing support

**Why multiple levels?** National trends can mask local problems - one province might be fine while another suffers major disruptions.

---

## Example: National vs. Provincial View

**National ANC1 (March 2023):**
- Expected: 50,000 visits
- Actual: 48,000 visits
- Shortfall: -2,000 (4% below expected) - **looks minor**

**But breaking down by province:**

| Province | Expected | Actual | Shortfall |
|----------|----------|--------|-----------|
| North | 15,000 | 14,800 | -200 (1%) |
| South | 20,000 | 19,900 | -100 (0.5%) |
| **East** | **15,000** | **13,300** | **-1,700 (11%)** |

**East Province has a serious problem** that's hidden in the national average!

---

## Interpreting Disruption Results

---

## Key Questions to Ask

**1. Which services are most disrupted?**
- Maternal health? Child health? Specific diseases?
- Are all services affected equally or just certain ones?

**2. When did disruptions occur?**
- Can we link to known events (strikes, campaigns, outbreaks)?
- Are they one-time or ongoing?

**3. Where are disruptions concentrated?**
- Which geographic areas are most affected?
- Urban vs. rural patterns?

**4. How severe are the impacts?**
- How many people missed services?
- What's the percentage change?

---

## Using Results for Decision-Making

**For program managers:**

**Immediate actions:**
- Investigate cause of detected disruptions
- Plan catch-up services for areas with large shortfalls
- Allocate resources to most-affected areas

**Strategic planning:**
- Identify chronic problem areas needing system strengthening
- Evaluate impact of policies or reforms
- Set realistic targets based on actual patterns

**Monitoring:**
- Track whether interventions improve service delivery
- Early warning system for emerging problems

---

## For Data Analysts

**Analysis workflow:**

1. **Review disruption flags:** Which months/areas were flagged?
2. **Examine magnitude:** Are shortfalls large enough to act on?
3. **Check data quality:** Could this be a data reporting issue?
4. **Contextualize:** What events might explain the pattern?
5. **Communicate findings:** Create visualizations and key messages

**Key outputs to share:**
- Lists of disrupted periods by indicator and area
- Shortfall estimates (numbers and percentages)
- Time series graphs showing expected vs. actual
- Maps showing geographic distribution of disruptions

---

## Common Questions

---

## "How do you know what 'expected' should be?"

**We use your own historical data:**

- Look at past 2-3 years of data for each area
- Account for seasonal patterns (some months naturally higher/lower)
- Account for long-term trends (gradual increases/decreases)
- Each area has its own "normal" based on its own history

**Example:**
- Rural clinic's "normal": 50 deliveries/month
- Urban hospital's "normal": 500 deliveries/month
- Each compared to its own baseline, not to each other

---

## "What if services are always low - is that a disruption?"

**No - disruption means a CHANGE from the usual pattern.**

**If services have always been low:**
- That's a chronic access problem, not a disruption
- Important issue but requires different response (system strengthening)

**A disruption is:**
- Services that WERE at some level
- Then DROP (or increase) significantly
- Compared to their own baseline

**Both matter** - but disruption detection helps you spot new/emerging problems distinct from existing chronic issues.

---

## "Could this just be a reporting problem?"

**Yes, sometimes! That's why data quality work (Module 1-2) comes first.**

**FASTR helps distinguish:**

**Real service disruption:**
- Affects multiple related indicators (ANC, deliveries, postnatal all drop together)
- Matches known events (strike, outbreak, policy change)
- Persists across months
- Other data sources confirm

**Data quality issue:**
- Only one indicator affected while others normal
- No plausible explanation for drop
- Inconsistent with facility reports or surveys
- Returns to normal next month with no intervention

**Always cross-check with program knowledge and other data sources.**

---

## "What about normal seasonal variation?"

**FASTR accounts for this automatically.**

**Example - Malaria services:**
- Naturally higher during rainy season
- Lower during dry season
- This is NOT flagged as a disruption

**How it works:**
- Looks at seasonal patterns in historical data
- Expects higher malaria in rainy season
- Only flags if it's unusual EVEN accounting for the season

**Example:**
- April usually has 1,000 malaria cases (rainy season)
- This April has only 600 cases
- Flagged as disruption (low even for rainy season)

---

## Key Takeaways

---

## Remember These Points

**1. Disruptions are changes from expected patterns**
- Not about absolute levels, but deviations from normal
- Each area compared to its own baseline

**2. Two-part analysis**
- WHEN: Identify months with unusual patterns
- HOW MUCH: Quantify the impact (shortfalls/surpluses)

**3. Multiple perspectives matter**
- National trends can hide local problems
- Look at provincial and district levels

**4. Context is essential**
- Link disruptions to known events
- Cross-check with data quality assessments
- Verify with program staff and other data

**5. Use for action**
- Identify areas needing support
- Quantify catch-up service needs
- Monitor impact of interventions

---

## What's Next?

**Now that we can track service delivery patterns, we can ask:**

**Module 4: Coverage Estimation**
- What percentage of the population is being reached?
- Are we meeting coverage targets?
- Where are the biggest gaps?

**Coverage adds the population perspective** - not just how many services, but what proportion of people who need them are getting them.

---
